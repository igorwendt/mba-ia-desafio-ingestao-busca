# Ingest√£o e Busca Sem√¢ntica com LangChain + PostgreSQL (pgVector)

Sistema de ingest√£o e busca sem√¢ntica sobre PDFs utilizando LangChain, PostgreSQL (pgVector) e m√∫ltiplos provedores de embeddings (HuggingFace, OpenAI, Google). Suporte a escolha din√¢mica de provedor via vari√°vel de ambiente ou argumento de linha de comando.

## üöÄ Funcionalidades

- **Ingest√£o**: L√™ PDF e armazena embeddings no PostgreSQL (pgVector)
- **Busca Sem√¢ntica**: Perguntas respondidas somente com base no conte√∫do ingerido
- **M√∫ltiplos Provedores de Embeddings**: `huggingface` (padr√£o ingest), `openai`, `google`
- **Cole√ß√µes Isoladas por Provedor**: Evita conflito de dimens√µes (ex: 384 vs 1536 vs 3072)
- **Contexto Restrito**: Nunca inventa conte√∫do fora do PDF

## üìã Pr√©-requisitos

- Python 3.9+
- Docker e Docker Compose
- HuggingFace embeddings (gratuitos, default na ingest√£o)
- (Opcional) Chave OpenAI se usar `--provider openai`
- (Opcional) Chave Google Generative AI se usar `--provider google`

## üõ†Ô∏è Instala√ß√£o

### 1. Clone o reposit√≥rio
```bash
git clone <seu-repositorio>
cd mba-ia-desafio-ingestao-busca
```

### 2. Crie e ative um ambiente virtual
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

### 3. Instale as depend√™ncias
```bash
pip install -r requirements.txt
```

### 4. Configure as vari√°veis de ambiente
Crie um arquivo `.env` (exemplo m√≠nimo):
```bash
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/vectordb
PDF_PATH=document.pdf

# Provedor padr√£o para busca (openai | google) ‚Äî ingest usa huggingface por padr√£o
EMBEDDING_PROVIDER=openai

# OpenAI (se usar)
OPENAI_API_KEY=sk-...
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Google (se usar)
GOOGLE_API_KEY=AIza...
GOOGLE_EMBEDDING_MODEL=models/gemini-embedding-001

# HuggingFace
HUGGINGFACE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Modelo LLM de resposta (chat)
GPT_MODEL=gpt-5-nano
```

## üèÉ‚Äç‚ôÇÔ∏è Execu√ß√£o

### 1. Subir o banco de dados
```bash
docker compose up -d
```

### 2. Executar ingest√£o do PDF (gera vetores)
```bash
source venv/bin/activate  # Ativar ambiente virtual
python src/ingest.py                   # Usa huggingface (padr√£o)
python src/ingest.py --provider openai # Opcional
python src/ingest.py --provider google # Opcional
```

### 3. Rodar o chat / busca
```bash
source venv/bin/activate  # Ativar ambiente virtual
python src/search.py --provider openai -q "Qual o faturamento da delta petroleo epp?"
python src/chat.py                        # usa EMBEDDING_PROVIDER do .env
python src/chat.py --provider google      # for√ßa provedor
```

## üí¨ Como usar o Chat

Ap√≥s executar `python src/chat.py`, voc√™ pode:

- Fazer perguntas sobre o conte√∫do do PDF
- Digitar `ajuda` para ver instru√ß√µes
- Digitar `sair` para encerrar

### Exemplo de uso:
```
=== Chat com Documentos ===
Digite 'sair' para encerrar o chat
Digite 'ajuda' para ver instru√ß√µes
----------------------------------------
Chat iniciado com sucesso!
----------------------------------------

Voc√™: Qual o faturamento da Empresa SuperTechIABrazil?
Assistente: O faturamento foi de 10 milh√µes de reais.

Voc√™: Quantos clientes temos em 2024?
Assistente: N√£o tenho informa√ß√µes necess√°rias para responder sua pergunta.
```

## üèóÔ∏è Estrutura do Projeto

```
‚îú‚îÄ‚îÄ docker-compose.yml      # Configura√ß√£o do PostgreSQL
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python
‚îú‚îÄ‚îÄ .env.example           # Template das vari√°veis de ambiente
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py         # Script de ingest√£o do PDF
‚îÇ   ‚îú‚îÄ‚îÄ search.py         # Script de busca sem√¢ntica
‚îÇ   ‚îú‚îÄ‚îÄ chat.py           # CLI para intera√ß√£o com usu√°rio
‚îú‚îÄ‚îÄ document.pdf          # PDF para ingest√£o
‚îî‚îÄ‚îÄ README.md            # Este arquivo
```

## üîß Configura√ß√£o

### Vari√°veis de Ambiente Principais
| Vari√°vel | Descri√ß√£o |
|----------|-----------|
| DATABASE_URL | String de conex√£o Postgres |
| PDF_PATH | Caminho do PDF a ser ingerido |
| EMBEDDING_PROVIDER | Provedor usado na busca (`openai` ou `google`) |
| OPENAI_API_KEY | API key OpenAI (se usar) |
| OPENAI_EMBEDDING_MODEL | Modelo embeddings OpenAI (default text-embedding-3-small) |
| GOOGLE_API_KEY | API key Google Generative AI (se usar) |
| GOOGLE_EMBEDDING_MODEL | Modelo embeddings Google (default text-embedding-004) |
| HUGGINGFACE_EMBEDDING_MODEL | Modelo HuggingFace (default MiniLM) |
| GPT_MODEL | Modelo LLM para resposta (ex: gpt-5-nano) |

Observa√ß√£o: a ingest√£o padr√£o usa HuggingFace para evitar custo. A busca pode ser feita com outro provedor desde que voc√™ tenha ingerido previamente para aquele provedor.

### Par√¢metros T√©cnicos
- **Chunk Size**: 1000 caracteres
- **Overlap**: 150 caracteres
- **Top-K** (retrieval): 10 (`similarity_search_with_score`)
- **LLM**: GPT (default `gpt-5-nano` via OpenAI API wrapper)
- **Embeddings suportados**:
	- HuggingFace: sentence-transformers/all-MiniLM-L6-v2 (384 dims)
	- OpenAI: text-embedding-3-small (1536 dims)
	- Google: gemini-embedding-001 (normalmente 768 ou 3072 dims conforme rota)
	- Cole√ß√µes separadas impedem conflito de dimens√£o.

### Cole√ß√µes por Provedor
Ao ingerir criamos cole√ß√µes distintas no Postgres:
```
documents_huggingface
documents_openai
documents_google
```
Isso evita o erro: `different vector dimensions 384 and 3072`.

### Migra√ß√£o de Vers√µes Anteriores
Se voc√™ tinha apenas a cole√ß√£o `documents` (antiga):
1. Ela ainda existe ‚Äì n√£o √© usada pelo novo c√≥digo.
2. Re-ingira para cada provedor que deseja usar.
3. (Opcional) Limpeza manual:
```sql
DELETE FROM langchain_pg_collection WHERE name = 'documents';
DELETE FROM langchain_pg_embedding WHERE collection_id NOT IN (SELECT uuid FROM langchain_pg_collection);
```

## üêõ Solu√ß√£o de Problemas

### Erro de conex√£o com banco
```bash
# Verificar se o Docker est√° rodando
docker compose ps

# Recriar o banco se necess√°rio
docker compose down
docker compose up -d
```

### Erro: different vector dimensions 384 and 3072
Voc√™ est√° tentando consultar uma cole√ß√£o povoada com embeddings de outro provedor. Solu√ß√£o: re-ingira usando o mesmo provedor ou especifique `--provider` correto.

### Erro de API Key
- HuggingFace: n√£o requer chave
- OpenAI: defina `OPENAI_API_KEY`
- Google: defina `GOOGLE_API_KEY`

### Erro de PDF n√£o encontrado
- Verifique se o arquivo `document.pdf` est√° na raiz do projeto
- Confirme o caminho no arquivo `.env`

## üìö Tecnologias Utilizadas

- **Python 3.9+**
- **LangChain** - Framework para aplica√ß√µes com LLM
- **PostgreSQL + pgVector** - Banco vetorial
- **HuggingFace** - Embeddings gratuitos e locais
- **OpenAI** - Embeddings + LLM
- **Google Generative AI** - Embeddings alternativos
- **Docker** - Containeriza√ß√£o do banco
- **PyPDF** - Processamento de PDF

## üìÑ Licen√ßa

Este projeto foi desenvolvido para o desafio MBA Engenharia de Software com IA - Full Cycle.